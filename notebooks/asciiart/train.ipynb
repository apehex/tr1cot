{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "34cac24c-df25-49a7-9828-5518a31df8bc",
      "metadata": {
        "id": "34cac24c-df25-49a7-9828-5518a31df8bc",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Text Diffusion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69ea0189-8329-49be-830a-3e22f50ee3c5",
      "metadata": {
        "id": "69ea0189-8329-49be-830a-3e22f50ee3c5",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Install The Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dnwEwhV4SrD",
      "metadata": {
        "id": "4dnwEwhV4SrD",
        "pycharm": {
          "name": "#%%\n",
          "is_executing": true
        }
      },
      "outputs": [],
      "source": [
        "!pip install -U accelerate datasets densecurves diffusers[training] torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import math\n",
        "import os\n",
        "\n",
        "import accelerate\n",
        "import accelerate.utils\n",
        "import datasets\n",
        "import diffusers\n",
        "import diffusers.optimization\n",
        "import torch\n",
        "import torch.nn.functional\n",
        "import torchvision\n",
        "import tqdm\n",
        "\n",
        "import PIL as pillow\n",
        "import matplotlib.pyplot as pyplot"
      ],
      "metadata": {
        "id": "mHaZkzcCMkNa"
      },
      "id": "mHaZkzcCMkNa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define The Config"
      ],
      "metadata": {
        "id": "RxNA-50bL9wZ"
      },
      "id": "RxNA-50bL9wZ"
    },
    {
      "cell_type": "code",
      "source": [
        "# BASE #########################################################################\n",
        "\n",
        "BASE_CONFIG = {\n",
        "    'height_dim': 128,\n",
        "    'width_dim': 128,}"
      ],
      "metadata": {
        "id": "xO2qUforZhIW"
      },
      "id": "xO2qUforZhIW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RANDOM #######################################################################\n",
        "\n",
        "RANDOM_CONFIG = {\n",
        "    'seed': 1337,}"
      ],
      "metadata": {
        "id": "KOTeIKQWa1_G"
      },
      "id": "KOTeIKQWa1_G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f740dfe-e610-4479-ac30-cce1f9e62553",
      "metadata": {
        "id": "1f740dfe-e610-4479-ac30-cce1f9e62553",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# MODEL ########################################################################\n",
        "\n",
        "MODEL_CONFIG = {\n",
        "    'sample_size': BASE_CONFIG['height_dim'],\n",
        "    'in_channels': 3,\n",
        "    'out_channels': 3,\n",
        "    'layers_per_block': 2,\n",
        "    'block_out_channels': (128, 128, 256, 256, 512, 512),\n",
        "    'down_block_types': ('DownBlock2D', 'DownBlock2D', 'DownBlock2D', 'DownBlock2D', 'AttnDownBlock2D', 'DownBlock2D',),\n",
        "    'up_block_types': ('UpBlock2D', 'AttnUpBlock2D', 'UpBlock2D', 'UpBlock2D', 'UpBlock2D', 'UpBlock2D'),\n",
        "    # 'attention_head_dim': 8,\n",
        "    # 'center_input_sample': False,\n",
        "    # 'downsample_padding': 1,\n",
        "    # 'flip_sin_to_cos': True,\n",
        "    # 'freq_shift': 0,\n",
        "    # 'mid_block_scale_factor': 1,\n",
        "    'act_fn': 'silu',\n",
        "    'norm_eps': 1e-05,\n",
        "    'norm_num_groups': 16,}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PATH #########################################################################\n",
        "\n",
        "PATH_CONFIG = {\n",
        "    'output_dir': 'output',\n",
        "    'cache_dir': '.cache',\n",
        "    'logging_dir': 'logs',}"
      ],
      "metadata": {
        "id": "EGDWmAdgaU3C"
      },
      "id": "EGDWmAdgaU3C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DATASET ######################################################################\n",
        "\n",
        "DATASET_CONFIG = {\n",
        "    'path': 'huggan/smithsonian_butterflies_subset',\n",
        "    'name': None,\n",
        "    'split': 'train',\n",
        "    'cache_dir': PATH_CONFIG['cache_dir'],}"
      ],
      "metadata": {
        "id": "pKXT-0h-fOA7"
      },
      "id": "pKXT-0h-fOA7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CHECKPOINT ###################################################################\n",
        "\n",
        "CHECKPOINT_CONFIG = {\n",
        "    'checkpoint_epoch_num': 4,}"
      ],
      "metadata": {
        "id": "EEeDDzcVaSSv"
      },
      "id": "EEeDDzcVaSSv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING #####################################################################\n",
        "\n",
        "ITERATION_CONFIG = {\n",
        "    'batch_size': 16,\n",
        "    'epoch_num': 32,\n",
        "    'step_num': 1000,}\n",
        "\n",
        "SCHEDULER_CONFIG = {\n",
        "    'num_warmup_steps': 512,\n",
        "    'num_training_steps': ITERATION_CONFIG['step_num'] * ITERATION_CONFIG['epoch_num'],}\n",
        "\n",
        "OPTIMIZER_CONFIG = {\n",
        "    'lr': 1e-4,\n",
        "    'betas': (0.9, 0.999),\n",
        "    'weight_decay': 1e-2,\n",
        "    'eps': 1e-8,}\n",
        "\n",
        "ACCELERATE_CONFIG = {\n",
        "    'sync_gradients': True,\n",
        "    'gradient_accumulation_steps': 1,\n",
        "    'mixed_precision': 'fp16',\n",
        "    'log_with': 'tensorboard',}"
      ],
      "metadata": {
        "id": "s0xeYQ9pMCG1"
      },
      "id": "s0xeYQ9pMCG1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DIFFUSION ####################################################################\n",
        "\n",
        "DIFFUSION_CONFIG = {\n",
        "    'batch_size': ITERATION_CONFIG['batch_size'],\n",
        "    'num_inference_steps': 1024,}"
      ],
      "metadata": {
        "id": "pgyTczelVu39"
      },
      "id": "pgyTczelVu39",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "09f4e50c-23d9-4057-ae37-c954d7e063bb",
      "metadata": {
        "id": "09f4e50c-23d9-4057-ae37-c954d7e063bb",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Download The Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1aaf676d-e992-4606-9116-f0324de50772",
      "metadata": {
        "id": "1aaf676d-e992-4606-9116-f0324de50772",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# DOWNLOAD #####################################################################\n",
        "\n",
        "dataset = datasets.load_dataset(**DATASET_CONFIG)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "tnv1mnmWYZoK",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "id": "tnv1mnmWYZoK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CHECK ########################################################################\n",
        "\n",
        "fig, axs = pyplot.subplots(1, 4, figsize=(16, 4))\n",
        "for i, image in enumerate(dataset[:4]['image']):\n",
        "    axs[i].imshow(image)\n",
        "    axs[i].set_axis_off()\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "AchvRobca31r",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "id": "AchvRobca31r",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess The Dataset"
      ],
      "metadata": {
        "id": "Hk77N2LTkWtg"
      },
      "id": "Hk77N2LTkWtg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83158bea-273e-4088-a75a-e3c7cc86e0fc",
      "metadata": {
        "id": "83158bea-273e-4088-a75a-e3c7cc86e0fc",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# OPERATIONS ###################################################################\n",
        "\n",
        "preprocess = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize((BASE_CONFIG['height_dim'], BASE_CONFIG['width_dim'])),\n",
        "    torchvision.transforms.RandomHorizontalFlip(),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize([0.5], [0.5]),])\n",
        "\n",
        "def transform(examples):\n",
        "    return {'images': [preprocess(__i.convert('RGB')) for __i in examples['image']]}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# APPLY ########################################################################\n",
        "\n",
        "dataset.set_transform(transform)"
      ],
      "metadata": {
        "id": "eBdbdooxe9am",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "id": "eBdbdooxe9am",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CHECK ########################################################################\n",
        "\n",
        "fig, axs = pyplot.subplots(1, 4, figsize=(16, 4))\n",
        "for i, image in enumerate(dataset[:4]['images']):\n",
        "    axs[i].imshow(image.permute(1, 2, 0).numpy() / 2 + 0.5)\n",
        "    axs[i].set_axis_off()\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "3YcuQZXafk0g",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "id": "3YcuQZXafk0g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# COLLATE ######################################################################\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(dataset, batch_size=ITERATION_CONFIG['batch_size'], shuffle=True)"
      ],
      "metadata": {
        "id": "rjBFh_8HpVam",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "id": "rjBFh_8HpVam",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Init The Model"
      ],
      "metadata": {
        "id": "uBcEpyrRk_U6"
      },
      "id": "uBcEpyrRk_U6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3eb5811-c10b-4dae-a58d-9583c42e7f57",
      "metadata": {
        "id": "e3eb5811-c10b-4dae-a58d-9583c42e7f57",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# CREATE #######################################################################\n",
        "\n",
        "model = diffusers.UNet2DModel(**MODEL_CONFIG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cd51b19-c237-4ddf-be90-b22db18f919f",
      "metadata": {
        "id": "7cd51b19-c237-4ddf-be90-b22db18f919f",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# RUN ##########################################################################\n",
        "\n",
        "sample_image = dataset[0]['images'].unsqueeze(0)\n",
        "\n",
        "print('Input shape:', sample_image.shape)\n",
        "print('Output shape:', model(sample_image, timestep=0).sample.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup The Training Env"
      ],
      "metadata": {
        "id": "n8izJfeH1kfJ"
      },
      "id": "n8izJfeH1kfJ"
    },
    {
      "cell_type": "code",
      "source": [
        "# PATHS ########################################################################\n",
        "\n",
        "os.makedirs(PATH_CONFIG['cache_dir'], exist_ok=True)\n",
        "os.makedirs(PATH_CONFIG['output_dir'], exist_ok=True)\n",
        "os.makedirs(PATH_CONFIG['logging_dir'], exist_ok=True)"
      ],
      "metadata": {
        "id": "6ZPXsN3z1pHK"
      },
      "id": "6ZPXsN3z1pHK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "575a059d-a849-449e-8e11-72abc9c9fe2d",
      "metadata": {
        "id": "575a059d-a849-449e-8e11-72abc9c9fe2d",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# SCHEDULER ####################################################################\n",
        "\n",
        "noise_scheduler = diffusers.DDPMScheduler(num_train_timesteps=ITERATION_CONFIG['step_num'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SCRAMBLE #####################################################################\n",
        "\n",
        "noise = torch.randn(sample_image.shape)\n",
        "timesteps = torch.LongTensor([50])\n",
        "noisy_image = noise_scheduler.add_noise(sample_image, noise, timesteps)\n",
        "\n",
        "pillow.Image.fromarray(((noisy_image.permute(0, 2, 3, 1) + 1.0) * 127.5).type(torch.uint8).numpy()[0])"
      ],
      "metadata": {
        "id": "SWIDblOdu4Sg",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "id": "SWIDblOdu4Sg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noise_pred = model(noisy_image, timesteps).sample\n",
        "loss = torch.nn.functional.mse_loss(noise_pred, noise)"
      ],
      "metadata": {
        "id": "JsK5WWwvv8gM",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "id": "JsK5WWwvv8gM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddbb43de-6e4f-43f3-929c-aae82b1c648b",
      "metadata": {
        "id": "ddbb43de-6e4f-43f3-929c-aae82b1c648b",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), **OPTIMIZER_CONFIG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a60ae2a8-9e72-4be2-8954-b8532cf323ee",
      "metadata": {
        "id": "a60ae2a8-9e72-4be2-8954-b8532cf323ee",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "lr_scheduler = diffusers.optimization.get_cosine_schedule_with_warmup(\n",
        "    optimizer=optimizer,\n",
        "    **SCHEDULER_CONFIG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwxUwlLBw-O1",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# DATAVIZ ######################################################################\n",
        "\n",
        "def make_grid(images, rows, cols):\n",
        "    w, h = images[0].size\n",
        "    grid = pillow.Image.new('RGB', size=(cols*w, rows*h))\n",
        "    for i, image in enumerate(images):\n",
        "        grid.paste(image, box=(i%cols*w, i//cols*h))\n",
        "    return grid\n",
        "\n",
        "def evaluate(config, epoch, pipeline):\n",
        "    # Sample some images from random noise (this is the backward diffusion process).\n",
        "    # The default pipeline output type is `List[PIL.Image]`\n",
        "    images = pipeline(\n",
        "        batch_size=config['batch_size'],\n",
        "        num_inference_steps=config['num_inference_steps'],\n",
        "        generator=torch.manual_seed(config['seed'])).images\n",
        "\n",
        "    # Make a grid out of the images\n",
        "    image_grid = make_grid(images, rows=4, cols=4)\n",
        "\n",
        "    # Save the images\n",
        "    test_dir = os.path.join(config['output_dir'], 'samples')\n",
        "    os.makedirs(test_dir, exist_ok=True)\n",
        "    image_grid.save(f'{test_dir}/{epoch:04d}.png')"
      ],
      "id": "pwxUwlLBw-O1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67640279-979b-490d-80fe-65673b94ae00",
      "metadata": {
        "id": "67640279-979b-490d-80fe-65673b94ae00",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def train_loop(config, model, noise_scheduler, optimizer, train_dataloader, lr_scheduler):\n",
        "    # Initialize accelerator and tensorboard logging\n",
        "    project_config = accelerate.utils.ProjectConfiguration(\n",
        "        project_dir=config['output_dir'],\n",
        "        logging_dir=config['logging_dir'])\n",
        "    accelerator = accelerate.Accelerator(\n",
        "        mixed_precision=config['mixed_precision'],\n",
        "        gradient_accumulation_steps=config['gradient_accumulation_steps'],\n",
        "        log_with=config['log_with'],\n",
        "        project_config=project_config)\n",
        "    if accelerator.is_main_process:\n",
        "        accelerator.init_trackers('train_example')\n",
        "\n",
        "    # Prepare everything\n",
        "    model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(\n",
        "        model, optimizer, train_dataloader, lr_scheduler)\n",
        "\n",
        "    global_step = 0\n",
        "\n",
        "    # Now you train the model\n",
        "    for epoch in range(config['epoch_num']):\n",
        "        progress_bar = tqdm.auto.tqdm(total=len(train_dataloader), disable=not accelerator.is_local_main_process)\n",
        "        progress_bar.set_description(f'Epoch {epoch}')\n",
        "\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            clean_images = batch['images']\n",
        "            # Sample noise to add to the images\n",
        "            noise = torch.randn(clean_images.shape).to(clean_images.device)\n",
        "            bs = clean_images.shape[0]\n",
        "\n",
        "            # Sample a random timestep for each image\n",
        "            timesteps = torch.randint(0, noise_scheduler.config.num_train_timesteps, (bs,), device=clean_images.device).long()\n",
        "\n",
        "            # Add noise to the clean images according to the noise magnitude at each timestep\n",
        "            # (this is the forward diffusion process)\n",
        "            noisy_images = noise_scheduler.add_noise(clean_images, noise, timesteps)\n",
        "\n",
        "            with accelerator.accumulate(model):\n",
        "                # Predict the noise residual\n",
        "                noise_pred = model(noisy_images, timesteps, return_dict=False)[0]\n",
        "                loss = torch.nn.functional.mse_loss(noise_pred, noise)\n",
        "                accelerator.backward(loss)\n",
        "\n",
        "                accelerator.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                optimizer.step()\n",
        "                lr_scheduler.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "            progress_bar.update(1)\n",
        "            logs = {'loss': loss.detach().item(), 'lr': lr_scheduler.get_last_lr()[0], 'step': global_step}\n",
        "            progress_bar.set_postfix(**logs)\n",
        "            accelerator.log(logs, step=global_step)\n",
        "            global_step += 1\n",
        "\n",
        "        # After each epoch you optionally sample some demo images with evaluate() and save the model\n",
        "        if accelerator.is_main_process:\n",
        "            pipeline = diffusers.DDPMPipeline(unet=accelerator.unwrap_model(model), scheduler=noise_scheduler)\n",
        "\n",
        "            if (epoch + 1) % config['checkpoint_epoch_num'] == 0 or epoch == config['epoch_num'] - 1:\n",
        "                evaluate(config, epoch, pipeline)\n",
        "\n",
        "            if (epoch + 1) % config['checkpoint_epoch_num'] == 0 or epoch == config['epoch_num'] - 1:\n",
        "                pipeline.save_pretrained(config['output_dir'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69fbb01c-1d64-4496-a9f1-5799051c1032",
      "metadata": {
        "id": "69fbb01c-1d64-4496-a9f1-5799051c1032",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Let's train!\n",
        "\n",
        "Let's launch the training (including multi-GPU training) from the notebook using Accelerate's `notebook_launcher` function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b11ba8b7-eb8f-4e8e-88ae-6e4a2b68433e",
      "metadata": {
        "id": "b11ba8b7-eb8f-4e8e-88ae-6e4a2b68433e",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "args = ({**RANDOM_CONFIG, **PATH_CONFIG, **CHECKPOINT_CONFIG, **ITERATION_CONFIG, **ACCELERATE_CONFIG}, model, noise_scheduler, optimizer, train_dataloader, lr_scheduler)\n",
        "\n",
        "accelerate.notebook_launcher(train_loop, args, num_processes=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "W6pK8RonfSu0",
      "metadata": {
        "id": "W6pK8RonfSu0",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Let's have a look at the final image grid produced by the trained diffusion model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "r5PM6vOQPISl",
      "metadata": {
        "id": "r5PM6vOQPISl",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "sample_images = sorted(glob.glob(f'{PATH_CONFIG[\"output_dir\"]}/samples/*.png'))\n",
        "pillow.Image.open(sample_images[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inspect The Logs"
      ],
      "metadata": {
        "id": "knNu61uGDCtn"
      },
      "id": "knNu61uGDCtn"
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "-bJ3tB92HjSu",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "id": "-bJ3tB92HjSu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs"
      ],
      "metadata": {
        "id": "uQRHWNOwDHi7"
      },
      "id": "uQRHWNOwDHi7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o2RKPgKxZQnW"
      },
      "id": "o2RKPgKxZQnW",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}